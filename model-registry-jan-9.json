{
  "registry_version": "1.0",
  "updated_at": "2026-01-09",
  "models": [
    {
      "key": "deepseek-v3.2",
      "display_name": "DeepSeek V3.2",
      "vendor": "DeepSeek",
      "family": "DeepSeek V3",
      "variant": "V3.2",
      "modality": ["text"],
      "parameters": {
        "total_b": 685,
        "active_b": null,
        "architecture": "MoE",
        "notes": "Total parameter count commonly reported; active parameters vary by routing and provider."
      },
      "context_window_tokens": 128000,
      "capabilities": {
        "vision": false,
        "tool_calling": true,
        "structured_output": "unknown"
      },
      "open_weights": "unknown",
      "license": "unknown",
      "best_for": [
        "general academic writing and revision",
        "coding assistance and debugging",
        "multi-step reasoning and structured planning",
        "information extraction and formatting (tables, bullet summaries, JSON drafts)"
      ],
      "strengths": [
        "strong general-purpose performance across writing + code",
        "handles long prompts and multi-part instructions well",
        "good at producing structured, organized outputs"
      ],
      "limitations": [
        "no image input",
        "tool-calling behavior depends on provider/template"
      ],
      "tags": [
        "general",
        "reasoning",
        "coding",
        "long_context",
        "tool_use"
      ],
      "ui_badges": ["Long context", "Tool use"]
    },
    {
      "key": "kimi-k2-thinking",
      "display_name": "Kimi K2 Thinking",
      "vendor": "MoonshotAI",
      "family": "Kimi K2",
      "variant": "Thinking",
      "modality": ["text"],
      "parameters": {
        "total_b": 1000,
        "active_b": 32,
        "architecture": "MoE",
        "notes": "MoE: 1T total / 32B active commonly listed by providers."
      },
      "context_window_tokens": 256000,
      "capabilities": {
        "vision": false,
        "tool_calling": true,
        "structured_output": "unknown"
      },
      "open_weights": false,
      "license": "proprietary",
      "best_for": [
        "very long-document reading and synthesis",
        "multi-document comparison (policies, articles, book chapters)",
        "large-context coding tasks (many files/snippets in one session)",
        "building and maintaining coherent project plans across long chats"
      ],
      "strengths": [
        "excellent at staying coherent with very large context",
        "strong reasoning mode for complex, multi-step tasks"
      ],
      "limitations": [
        "no image input",
        "higher latency/cost typical for very large-context models"
      ],
      "tags": [
        "long_context",
        "reasoning",
        "synthesis",
        "tool_use"
      ],
      "ui_badges": ["Very long context", "Tool use"]
    },
    {
      "key": "glm-4.6",
      "display_name": "GLM 4.6",
      "vendor": "Z.AI (Zhipu)",
      "family": "GLM",
      "variant": "4.6",
      "modality": ["text"],
      "parameters": {
        "total_b": 357,
        "active_b": null,
        "architecture": "unknown",
        "notes": "Parameter count commonly listed by providers; architecture details vary."
      },
      "context_window_tokens": 200000,
      "capabilities": {
        "vision": false,
        "tool_calling": true,
        "structured_output": "unknown"
      },
      "open_weights": false,
      "license": "proprietary",
      "best_for": [
        "long-context writing and analysis",
        "multilingual drafting and translation workflows",
        "extraction/classification pipelines with tool use",
        "comparison baseline against other long-context models"
      ],
      "strengths": [
        "strong long-context handling",
        "good multilingual coverage (provider-dependent)"
      ],
      "limitations": [
        "no image input",
        "tool-calling behavior depends on provider/template"
      ],
      "tags": [
        "long_context",
        "multilingual",
        "general",
        "tool_use"
      ],
      "ui_badges": ["Long context", "Tool use"]
    },
    {
      "key": "gpt-oss-120b",
      "display_name": "gpt-oss-120b",
      "vendor": "OpenAI",
      "family": "gpt-oss",
      "variant": "120b",
      "modality": ["text"],
      "parameters": {
        "total_b": 117,
        "active_b": 5.1,
        "architecture": "MoE",
        "notes": "Often described as ~117B total with ~5.1B active."
      },
      "context_window_tokens": 131072,
      "capabilities": {
        "vision": false,
        "tool_calling": true,
        "structured_output": "unknown"
      },
      "open_weights": true,
      "license": "unknown",
      "best_for": [
        "reproducible open-weights workflows",
        "structured outputs and schema-following tasks",
        "evaluation baselines and benchmarking across tasks",
        "agent-style tool workflows (provider-dependent)"
      ],
      "strengths": [
        "open-weights option with strong instruction-following",
        "good candidate for standardized evaluation across courses/projects"
      ],
      "limitations": [
        "no image input",
        "tool-calling behavior depends on provider/template"
      ],
      "tags": [
        "open_weights",
        "reasoning",
        "general",
        "tool_use",
        "evaluation_baseline"
      ],
      "ui_badges": ["Open weights", "Tool use"]
    },
    {
      "key": "qwen3-235b-a22b",
      "display_name": "Qwen3 235B A22B",
      "vendor": "Qwen (Alibaba)",
      "family": "Qwen3",
      "variant": "235B A22B",
      "modality": ["text"],
      "parameters": {
        "total_b": 235,
        "active_b": 22,
        "architecture": "MoE",
        "notes": "MoE: 235B total / 22B active."
      },
      "context_window_tokens": 32768,
      "capabilities": {
        "vision": false,
        "tool_calling": true,
        "structured_output": "unknown",
        "reasoning_mode": true
      },
      "open_weights": "unknown",
      "license": "unknown",
      "best_for": [
        "tool-using agents (multi-step workflows with external actions)",
        "multilingual tutoring and writing support",
        "coding plus reasoning-mode tasks",
        "classification/extraction plus summarization pipelines"
      ],
      "strengths": [
        "strong agent/tool behavior when templates are set up well",
        "good multilingual breadth",
        "useful reasoning-mode variant"
      ],
      "limitations": [
        "no image input",
        "native context is smaller than the 128K+ long-context models unless using provider extensions"
      ],
      "tags": [
        "agentic",
        "tool_use",
        "multilingual",
        "reasoning",
        "coding"
      ],
      "ui_badges": ["Tool use", "Reasoning mode"]
    },
    {
      "key": "gemma-3-27b-it",
      "display_name": "Gemma 3 27B (IT)",
      "vendor": "Google",
      "family": "Gemma 3",
      "variant": "27B IT",
      "modality": ["text", "image"],
      "parameters": {
        "total_b": 27,
        "active_b": null,
        "architecture": "dense",
        "notes": "Instruction-tuned variant; multimodal capability depends on deployment."
      },
      "context_window_tokens": 128000,
      "capabilities": {
        "vision": true,
        "tool_calling": "unknown",
        "structured_output": "unknown"
      },
      "open_weights": true,
      "license": "unknown",
      "best_for": [
        "everyday writing, summarization, and tutoring-style explanations",
        "image-based interpretation (figures, screenshots, diagrams) when enabled",
        "lower-latency alternative to very large models",
        "drafting and revision with long context"
      ],
      "strengths": [
        "vision-capable open model (deployment-dependent)",
        "strong quality-to-size tradeoff",
        "good long-context support"
      ],
      "limitations": [
        "vision availability depends on the exact endpoint/model variant served",
        "tool calling may require prompting conventions depending on provider"
      ],
      "tags": [
        "open_weights",
        "vision",
        "general",
        "long_context"
      ],
      "ui_badges": ["Open weights", "Vision", "Long context"]
    },
    {
      "key": "llama-3.1-70b-instruct",
      "display_name": "Llama 3.1 70B Instruct",
      "vendor": "Meta",
      "family": "Llama 3.1",
      "variant": "70B Instruct",
      "modality": ["text"],
      "parameters": {
        "total_b": 70,
        "active_b": null,
        "architecture": "dense",
        "notes": "Standard dense 70B class model."
      },
      "context_window_tokens": 128000,
      "capabilities": {
        "vision": false,
        "tool_calling": "unknown",
        "structured_output": "unknown"
      },
      "open_weights": true,
      "license": "unknown",
      "best_for": [
        "general academic chat and drafting",
        "revision and editorial assistance",
        "summarization and synthesis with long context",
        "evaluation baseline for comparisons across tasks"
      ],
      "strengths": [
        "reliable open model with strong general performance",
        "good baseline for side-by-side evaluation"
      ],
      "limitations": [
        "no image input",
        "tool calling depends on serving stack and prompt template"
      ],
      "tags": [
        "open_weights",
        "general",
        "long_context",
        "evaluation_baseline"
      ],
      "ui_badges": ["Open weights", "Long context"]
    }
  ]
}
